{"cells":[{"cell_type":"markdown","source":["### Producer: 2021 Air Quality USA by County"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec0b2953-0694-4fea-a770-b2c0f0bc174d"}}},{"cell_type":"code","source":["### imports\n\nimport requests\nimport json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"945d057d-962d-44c0-99ac-5fef32124d5d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Error callback functions\n\ndef error_cb(err):\n    \"\"\" The error callback is used for generic client errors. These\n        errors are generally to be considered informational as the client will\n        automatically try to recover from all errors, and no extra action\n        is typically required by the application.\n        For this example however, we terminate the application if the client\n        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n        authentication errors (_AUTHENTICATION). \"\"\"\n\n    print(\"Client error: {}\".format(err))\n    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n       err.code() == KafkaError._AUTHENTICATION:\n        # Any exception raised from this callback will be re-raised from the\n        # triggering flush() or poll() call.\n        raise KafkaException(err)\n\n\ndef acked(err, msg):\n    \"\"\" \n        Error callback is used for generic issues for producer errors. \n        \n        Parameters:\n            err (err): Error flag.\n            msg (str): Error message that was part of the callback.\n    \"\"\"\n    if err is not None:\n        print(\"Failed to deliver message: %s: %s\" % (str(msg), str(err)))\n    else:\n        print(\"Message produced: %s\" % (str(msg)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4d322a9-3fa7-4cc4-bd23-5bb3c2a72762"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Connection strings\n\nfrom confluent_kafka import Consumer\nfrom time import sleep\nimport uuid\nfrom confluent_kafka import Producer, Consumer, KafkaError, KafkaException\nimport json\nfrom confluent_kafka.admin import AdminClient, NewTopic\n\n\n#KAFKA variables, Move to the OS variables or configuration\n# This will work in local Jupyter Notebook, but in a databrick, hiding config.py is tougher. \nconfluentClusterName = \"stage3talent\"\nconfluentBootstrapServers = \"pkc-ldvmy.centralus.azure.confluent.cloud:9092\"\nconfluentTopicName = \"jadr-AQI\"\nschemaRegistryUrl = \"https://psrc-gq7pv.westus2.azure.confluent.cloud\"\nconfluentApiKey = dbutils.secrets.get(scope = \"jadr_blob\", key = \"confluentApiKey\")\nconfluentSecret = dbutils.secrets.get(scope = \"jadr_blob\", key = \"confluentSecret\")\nconfluentRegistryApiKey = dbutils.secrets.get(scope = \"jadr_blob\", key = \"confluentRegistryApiKey\")\nconfluentRegistrySecret = dbutils.secrets.get(scope = \"jadr_blob\", key = \"confluentRegistrySecret\")\n\n# Kafka admin setup\n\nadmin_client = AdminClient({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cba7e8c7-e4f2-4107-9738-c28fd062edba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Kafka Producer setup\n\np = Producer({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84760126-1127-4ff4-9483-7d4ad77558bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Create a Kafka topic\n\nfutures = admin_client.create_topics([NewTopic(confluentTopicName, 1, 3)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29476ce0-401f-43dd-bc15-3f96b937ef3a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["### The Producer Itself\n### 2021 Air Quality data, all counties in US, annual data\n# Documentation for API: https://aqs.epa.gov/aqsweb/documents/data_api.html#annual\n    # https://aqs.epa.gov/data/api/list/countiesByState?email=test@aqs.api&key=test&state=06      \n\n    \n# Variable declarations\nemail = \"dgerber@dev-10.com\"\nkey = confluentRegistrySecret = dbutils.secrets.get(scope = \"jadr_blob\", key = \"AQKey_dg\")\ndate = '2021'\nbdate = f\"{date}0101\"\nedate = f\"{date}1231\"\ncol_to_keep = [\"state_code\", \"county_code\", \"latitude\",\"longitude\",\"parameter\",\"metric_used\",\"method\",\"year\",\"units_of_measure\",\n               \"state\",\"county\",\"city\",\"arithmetic_mean\",\"standard_deviation\", \"first_max_value\", \"second_max_value\", \n               \"ninety_ninth_percentile\", \"cbsa_code\"]\n\n# This returns Lead (TSP) LC, Carbon monoxide, Sulfur dioxide, Nitrogen dioxide (NO2), Ozone, PM10 Total 0-10um STP, Lead PM10 LC FRM/FEM,  and PM2.5 - Local Conditions\nparams = \"14129,42401,42602,44201,81102,85129,88101\" \n\n# To get all states\nstates = []\nfor staterow in json.loads(requests.get(f'https://aqs.epa.gov/data/api/list/states?email={email}&key={key}').text)['Data']:\n    try:\n        code = int(staterow['code'])\n        if code < 66:\n            states.append(str(code).zfill(2))\n    except:\n        continue\n\n# Get data for each county from API, push to producer\nfor state in states:\n    stateurl = f'https://aqs.epa.gov/data/api/list/countiesByState?email={email}&key={key}&state={state}'\n    for countyrow in json.loads(requests.get(stateurl).text)['Data']:\n        county = countyrow['code']\n        URL = f'https://aqs.epa.gov/data/api/annualData/byCounty?email={email}&key={key}&param={params}&bdate={bdate}&edate={edate}&state={state}&county={county}'\n        for aDict in json.loads(requests.get(URL).text)['Data']:\n            p.produce(confluentTopicName,json.dumps(dict((k, aDict[k]) for k in col_to_keep))) # Grab only the columns we want, and append it to the list of dictionaries, push to producer\n            p.flush()\n            sleep(5)    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d20866df-8987-415b-8142-362bd875947f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Capstone Kafka Producer","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":522247351783547}},"nbformat":4,"nbformat_minor":0}
